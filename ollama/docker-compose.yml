services:
  ollama:
    image: docker.io/ollama/ollama:latest
    pull_policy: always
    tty: true
    restart: unless-stopped
    env_file:
      - .env
    volumes:
      - local-data:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    ports:
      - 11434:11434
    profiles:
      - local
      - nvidia

  o4a:
    image: docker.io/ollama/ollama:latest
    pull_policy: always
    tty: true
    restart: unless-stopped
    env_file:
      - .env
    volumes:
      - tailscale-data:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "ollama", "ps"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 10s
    network_mode: service:o4a-ts
    profiles:
      - tailscale
      - nvidia

  o4a-ts:
    image: tailscale/tailscale:latest
    environment:
      - TS_EXTRA_ARGS=--auth-key file:/run/secrets/tsauthkey --accept-dns --hostname o4a${ENV_TYPE}${ENV_SUFFIX}
      - TS_STATE_DIR=/var/lib/tailscale
      - TS_USERSPACE=false
    volumes:
      - tailscale-state:/var/lib/tailscale
    devices:
      - /dev/net/tun:/dev/net/tun
    cap_add:
      - net_admin
    restart: unless-stopped
    secrets:
      - tsauthkey
    healthcheck:
      test: ["CMD", "tailscale", "status"]
      interval: 10s
      timeout: 5s
      retries: 3
    profiles:
      - tailscale

secrets:
  tsauthkey:
    file: ~/.secrets/tsauthkey-tag-llm.key

volumes:
  local-data:
  tailscale-data:
  tailscale-state: